# Meeting : DATE

* Time: 15:00-15:30
* Location: SAWB 331
----------

* Project: Watermarking in Machine-Generated Text
* Student: Samuel Jackson
* Student ID: 2520998J
* Supervisor: Dr. Jake Lever
----------

### Agenda

- How Paraphrasers are Trained [5 mins]
- Attempts at GPT2 & LLaMa-2 [5 mins]
- How to generate content [10 mins]
- My plan for next week [5-10 mins]
- [ONLY IF READ KIRCHENBAUER PAPER] Discussion on watermarking technique [5 mins]

### Progress

- Tried out various GPT-2 models (untuned, different parameter numbers).
- Attempted implementing Kirchenbaueur's method.
- Researched & summarised basics of paraphrase training and datasets.
- Setup computer/environments for development.

### Questions

- To generate content, should I prepare prompts/find a prompt dataset?
- Is it necessary to have my own (code) implementation of the watermark method? 
- If I wanted to make improvements to the watermarking, should I leave this as an "if time" objective? 
  - Similarly, would I be able to introduce improvements/alterations without making the changes a focus of the paper?

#### Research Questions
- Does recursive paraphrasing evade the Stanford-Distortion watermarking method?
- Is the degradation of text perplexity linear through paraphrasing?
- Impact of short-context paraphraser vs long-context paraphraser?
- Feasibility of use in academic context?
- Is there a reasonable "minimum" text length for watermarking/paraphrasing?  

### Meeting Minutes

- Notes throughout session

### Summary

- Summary of meeting

### Next Meeting Goals

- Things to do for next meeting


