% REMEMBER: You must not plagiarise anything in your report. Be extremely careful.

\documentclass{l4proj}

    
% put any additional packages here
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{enumitem}


%==============================================================================
%% Commands 
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

\setitemize{noitemsep}
%==============================================================================

\begin{document}

%==============================================================================
%% METADATA
\title{Recursive Paraphrasing on AI-Watermarked Text}
\author{Samuel Jackson}
\date{\today}

\maketitle

%==============================================================================
%% ABSTRACT
\begin{abstract}
    \textbf{Every abstract follows a similar pattern. Motivate; set aims; describe work; explain results.}
    \vskip 0.5em
    Given the rise of LLMs and the growing power of malicious content-generation, 
    methods of identifying and authenticating machine-generated content has become a necessity. 
    This paper aims to investigate the robustness of modern techniques in watermarking LLMs at inference
    through paraphrasing attacks. The paper presents evidence of poor defense towards paraphrasing attacks
    where even a simple paraphraser can reduce detect-ability by ??\%.
\end{abstract}

%==============================================================================

% EDUCATION REUSE CONSENT FORM
% If you consent to your project being shown to future students for educational purposes
% then insert your name and the date below to  sign the education use form that appears in the front of the document. 
% You must explicitly give consent if you wish to do so.
% If you sign, your project may be included in the Hall of Fame if it scores particularly highly.
%
% Please note that you are under no obligation to sign 
% this declaration, but doing so would help future students.
%
%\def\consentname {My Name} % your full name
%\def\consentdate {20 March 2018} % the date you agree
%
\educationalconsent


%==============================================================================
\tableofcontents

%==============================================================================
%% Notes on formatting
%==============================================================================
% The first page, abstract and table of contents are numbered using Roman numerals and are not
% included in the page count. 
%
% From now on pages are numbered
% using Arabic numerals. Therefore, immediately after the first call to \chapter we need the call
% \pagenumbering{arabic} and this should be called once only in the document. 
%
% Do not alter the bibliography style.
%
% The first Chapter should then be on page 1. You are allowed 40 pages for a 40 credit project and 30 pages for a 
% 20 credit report. This includes everything numbered in Arabic numerals (excluding front matter) up
% to but excluding the appendices and bibliography.
%
% You must not alter text size (it is currently 10pt) or alter margins or spacing.
%
%
%==================================================================================================================================
%
% IMPORTANT
% The chapter headings here are **suggestions**. You don't have to follow this model if
% it doesn't fit your project. Every project should have an introduction and conclusion,
% however. 
%
%==================================================================================================================================
\chapter{Introduction}

% reset page numbering. Don't remove this!
\pagenumbering{arabic} 


Accredited to the rise of ChatGPT, we have seen Large Language Models (LLM) become mainstream alongside the text that they produce. The realistic appearance of unreliable text generated by these models fuels misinformation (reference), academic misconduct (reference) and fearmongering (reference). In an effort to help combat AI-generated text, methods of hiding digital signatures within text have been established, known as watermarks. 
\section{Guidance}

\textbf{Motivate} first, then state the general problem clearly. 

\section{Writing guidance}
\subsection{Who is the reader?}

This is the key question for any writing. Your reader:

\begin{itemize}
    \item
    is a trained computer scientist: \emph{don't explain basics}.
    \item
    has limited time: \emph{keep on topic}.
    \item
    has no idea why anyone would want to do this: \emph{motivate clearly}
    \item
    might not know \emph{anything} about your project in particular:
    \emph{explain your project}.
    \item
    but might know precise details and check them: \emph{be precise and
    strive for accuracy.}
    \item
    doesn't know or care about you: \emph{personal discussions are
    irrelevant}.
\end{itemize}

Remember, you will be marked by your supervisor and one or more members
of staff. You might also have your project read by a prize-awarding
committee or possibly a future employer. Bear that in mind.

\subsection{References and style guides}
There are many style guides on good English writing. You don't need to
read these, but they will improve how you write.

\begin{itemize}
    \item
    \emph{How to write a great research paper} \cite{Pey17} (\textbf{recommended}, even though you aren't writing a research paper)
    \item
    \emph{How to Write with Style} \cite{Von80}. Short and easy to read. Available online.
    \item
    \emph{Style: The Basics of Clarity and Grace} \cite{Wil09} A very popular modern English style guide.
    \item
    \emph{Politics and the English Language} \cite{Orw68}  A famous essay on effective, clear writing in English.
    \item
    \emph{The Elements of Style} \cite{StrWhi07} Outdated, and American, but a classic.
    \item
    \emph{The Sense of Style} \cite{Pin15} Excellent, though quite in-depth.
\end{itemize}

\subsubsection{Citation styles}

\begin{itemize}
\item If you are referring to a reference as a noun, then cite it as: ``\citet{Orw68} discusses the role of language in political thought.''
\item If you are referring implicitly to references, use: ``There are many good books on writing \citep{Orw68, Wil09, Pin15}.''
\end{itemize}

There is a complete guide on good citation practice by Peter Coxhead available here: \url{http://www.cs.bham.ac.uk/~pxc/refs/index.html}. 
If you are unsure about how to cite online sources, please see this guide: \url{https://student.unsw.edu.au/how-do-i-cite-electronic-sources}.

\subsection{Plagiarism warning}

\begin{highlight_title}{WARNING}
    
    If you include material from other sources without full and correct attribution, you are commiting plagiarism. The penalties for plagiarism are severe.
    Quote any included text and cite it correctly. Cite all images, figures, etc. clearly in the caption of the figure.
\end{highlight_title}


%==================================================================================================================================
\chapter{Background}
PROVIDE INTRO TO THIS BACKGROUND SECTION. 

\section{Text Generation}
    \subsection{Tokenization \& Vectorization}
        To process textual data through a computer, we provide a numerical representation of our data to the computer.
        
        The process of parsing text is known as \textit{tokenization}, where unstructured textual data is provided structure according to parser-based rules. A \textit{token} refers to a sequence of characters, be it a word or a subword. TALK ABOUT UNIQUENESS OF TOKENIZERS. 
        
        From this stage, the tokens are used in a vectorization map which takes a token to a vector representation, granting a numerical structure. UNIQUENESS OF VECTORIZATION  
        
    \subsection{Probabilities \& Logits}
        The probability of an event occurring is defined by a function $\rho: \Sigma \rightarrow [0,1]$, where $\Sigma$ is a sample space. While computers are most accurate between $[0,1]$, due to floating-point representation, it is often more useful to represent probabilities in the form of logits.

        \begin{definition}[Logits]
            Let $p$ be the probability of an event happening. The \textit{logit}, or log odds of the event occurring is defined as: 
            \begin{align}
                \text{logit}(p) = \log\bigg(\frac{p}{1-p}\bigg),
            \end{align}
            where logit is defined as $\text{logit}: (0,1) \rightarrow (-\infty, \infty)$.
        \end{definition}
        
        The low probability values become negative under this method. This feature, alongside the wide range of values, provides simple interpretability. Hence, logits have become convention within the NLP sphere.

        PROVIDE IMAGE SHOWING PROBABILITY VS LOGITS SIDE-BY-SIDE.

    \subsection{Language Modelling}
        A Large Language Model (LLM) is an data-intensive machine learning model, expensively trained on large amounts of text. The training process will vary dependent on objective, and the architecture changes correspondingly.

        Models focused on translation, summarization and paraphrasing tend to be Sequence to Sequence (Seq2Seq) models. Seq2Seq models use an encoder-decoder architecture, encoding each token with reference to the entire input. The decoding is then completed in a left-to-right sequence.
`
        Famous services like ChatGPT are Causal Language models, using a unidirectional (left-to-right) decoder architecture. This means, at each stage, the generation of a token is only based on the previous tokens. 

\section{Watermarks}
    \subsection{Content Watermarks}
        A \textit{watermark} is a faint figure or signature designed to represent ownership or authorship. Examples range from the American $5$ dollar bill to a music producer having an audio tag.
        
        IMAGE EXAMPLE OF WATERMARK

        The varying methods of portraying media and art has required that methods of watermarking similarly grow in variety and effectiveness. \citet{xiang2017digital} covers traditional methods of audio watermarking, such as echo hiding and spread spectrum, which aim to achieve imperceptibility by deceiving our hearing. 
        
        PROVIDE METHODS OF IMAGE WATERMARKING 

        To hide a signature within text is a different task as it does not have the opportunity to deceive audio, whereas visual sensor can only be deceived on a small scale. Historically, 
        
        TALK ABOUT FIRST CASES OF TEXT WATERMARKING. 
        
        Modern-day techniques use generative methods that allow for alterations in the text, be it the characters used or biasing particular tokens.
    \subsection{Text Watermark Requirements}
         Watermarks come in many forms, be it a signature: ``Written by Sam Jackson'' or a well-defined pattern of ending every word with the character `n'.
         
         Given the purpose of watermarking generative content, there are the following primary goals that an AI watermark aims to achieve:
         \begin{itemize}
            \setlength\itemsep{0.5em}
            \item \textbf{Robust} - Capable of withstanding attempts to remove watermark.
            \item \textbf{Agnostic} - Data beyond generated text is not required.
            \item \textbf{Imperceptible} - The watermark should not be visible, be it a change in quality or a written signature.
        \end{itemize}
        These requirements are specifically designed to encourage watermarks which are zero-shot and capable of covering all LLMs, as opposed to examples like ChatGPT detection \cite{perhaps an example/rewrite this}.
    \subsection{Attacking methods}
        No matter the robustness of a watermark, methods of successfully attacking are real threats. 

        A classic and simple technique is \textit{word-replacement}. This is a rule-based technique, free from computational constraints, which has success against models, as mentioned in \cite{reference here}, but suffers in textual clarity.

        Embedding generated-text within a larger document is a subtle method which can be successful. Students are known to have used AI for a particular paragraph or sentence of an essay, as opposed to the entire essay. Detection within a larger document is reported to be less successful \cite{okay okay, pray for the source} where only a small portion of the text is generated. 

        Opposing the prior methods, this method is particular to causal language modelling. Due to the nature of generative content, instructing the prompt can be an effective method to combat watermarking methods focused on manipulating the logits at inference time \cite{maryland, sorry bro}. 

        TALK ABOUT PARAPHRASING HERE.
        

\section{Paraphrasing}
    \subsection{English Definition \& Purpose}
        \begin{definition}[Paraphrase]
            To repeat something written or spoken using different words, often in a humorous form or in a simpler and shorter form that makes the original meaning clearer (Cambridge Dictionary, 2024).
        \end{definition}
    \subsection{Attacking Method}
        \begin{itemize}
            \setlength\itemsep{0.5em}
            \item Instead of altering generating content, the content is used as prompt.
            \item The model is funnelled through a Seq2Seq model (as opposed to causal), using an encoder-decoder architecture, to produce a paraphrase.
            \item By definition, defeats watermarkings methods like whitespacing and homoglyphs. 
        \end{itemize}
    \subsection{DIPPER Paraphrase Model}
        Paraphrasers tend to be Seq2Seq models, as the task is not too dissimilar to translation. In fact, many translators are trained on text which is twice-translated \citet{to french and back!}. Publicly available paraphrasers tend to be fine-tuned on sentence translations, leading to the sentence focus. Fortunately, there is one paper that generated their own paragraph-based paraphraser.

        A paper which focused on a retrieval-based defense also brought forwards a technique to fine-tune a paragraph-based 
        \begin{itemize}
            \setlength\itemsep{0.5em}
            \item Reference DIPPER paper
            \item Variability in paraphrasing 
            \item Paragraph context as opposed to sentence. 
        \end{itemize}

\section{Literature Survey}
    \subsection{Maryland Watermark}
        \begin{itemize}
            \setlength\itemsep{0.5em}
            \item Reference Kirchenbauer paper
            \item Discuss hard watermark method 
            \item Intro to soft watermark method
        \end{itemize}
    \subsection{Stanford Distortion Method}
    \subsection{Inevitable Failure of Deep-Learning Detection Methods}
    \subsection{Easy Watermarking Methods}

% This is just for me to remember. Not staying like this.
\section{Research Questions}
    Each section should have a reference to these questions in some way. i.e. How does this impact paraphrasing on a paragraph-level as opposed to sentence-based? 
    \subsection{Does recursive paraphrasing provide more effective removal of a watermark?}
    \subsection{Is text perplexity affected linearly through recursive paraphrasing?}
    \subsection{How does sentence-based paraphrasing compare to paragraph-based paraphrasing?}
    \subsection{Is there feasibility of use within an academic context?}
    
    
%================================================================================================
\chapter{Methods}
\textbf{What did you do to implement this idea, and what technical achievements did you make?}

\section{Dataset}
    \subsection{Source}
        From Kaggle, ongoing competition, aiming to detect AI Generated Text \citep{llm-detect-ai-generated-text}. 
    \subsection{Other possible datasets}
        I chose to opt for a instruct model as opposed to an auto-generated method. The auto-generated method was experimented with, with a dataset from SignalMedia 1M Articles. 
    \subsection{Information and Reliability}
        The dataset is composed of four columns: \textbf{id}, \textbf{text}, \textbf{instructions}, \textbf{source\_text}.
        The \textbf{text} column provides real essays, scraped from a separate Kaggle competition \cite{link feedback prize 3 kaggle}.

\section{Experimentation Approach}
    \subsection{Flow Chart}
        \begin{figure}[h]
            \centering
            \includegraphics[width=1\linewidth]{images/flow-charts/data-method-curved.pdf}
            \caption{Flow Chart describing the process of generating the evaluation data.}
            \label{fig:method-flow-chart} 
        \end{figure}

\section{Model Selection}
    \subsection{Limitations and Availability}
    \subsection{Prompt Generation}
    
\section{Implementation of Maryland Watermark}
    The Maryland Watermark \citep{kirchenbauer2023watermark} made the code publicly available, which aided in customising the method for my purposes.

    The implementation leverages the internals of HuggingFace and PyTorch. The figure \ref{fig:draw-this-figure} portrays the point at which changes are made. The post-training addition is a key selling point of the method, allowing for pre-existing models to adopt watermarking.

    DISPLAY PROCESS FIGURE HERE. 

    % Think about what else to discuss here. Perhaps the delta and gamma scores? I fix these in my work so maybe reference as to why.

\section{Fine-tuning of a Paraphraser}
    The DIPPER paper \citep{krishna2023paraphrasing} provided the dataset, which is a processed version of the Par3 dataset \citep{Par3_2022}. Whilst the fine-tuned model was similarly available, the computational cost was too great. Hence, I fine-tuned a lower-cost variation.

    \subsection{Chosen Model}
        Respecting the initial paper, T5 was the chosen Seq2Seq model architecture for the paraphrasing task. The pretrained model was designed to investigate the potential of transfer-learning, hence lending itself to paraphrasing comfortably. 

        Within T5, numerous options are available. The paper, presented by \citet{tay2022scale}, provides analysis into efficient scaling as well as model checkpoints to be exploited. Amongst the efficient models, a DeepNarrow architecture is recommended to improve performance. This led to the decision to fine-tune the T5-Efficient-Large-NL32, where NL32 refers to the number of transformer blocks and Large refers to the approximately 1 billion parameters.

    \subsection{Training Approach}
        The initial paper fine-tuned their model on $\sim$6,000,000 paraphrase pairs, taking between 384 and 768 GPU hours \citep{krishna2023paraphrasing}. Incapable of replicating the same compute periods, the model I produced was fine-tuned on 50,000 paraphrase pairs, taking 6 GPU hours. % (Fine-tune another, aim for 100,000 paraphrase pairs). 
        Further specifications into the training arguments are in the appendix. % Refer to appendix.

        % Should probably actually do this
        The dataset provided by DIPPER is split between Google translated and human translated. These sections are further split into nondescript subsections. In an effort to replicate the original paper to the fullest, both sections were sampled, taking a uniform distribution of documents from the respective subsections. 
        The dataset used is now publicly available. % (Make it publicly available)
        % (*) (Later 100,000 samples)
        
    \subsection{Flow Chart of Process}
        Is this necessary? ASK JAKE 
        
\section{Generating Results} % Name this something better
    The watermark can only be applied at inference stage, hence the data generation process required to begin with creating watermarked documents. 

    \subsection{Watermarking Documents}
        How did this process function? Provided a prompt, the chosen model would generate two essays, watermarked and unwatermarked. The generation was nucleus-sampling (should make it nucleus sampling) with $p = 0.8$ (give reasons for this?)

    \subsection{Paraphrasing Documents}
        This was a two pronged approach. Paraphrasing had to be completed many times, over many documents. Perhaps I could have used some distributed processing for this portion. 
        I had to paraphrase with a sentence-based paraphraser as well as a paragraph-based.

    \subsection{Evaluating Documents}
        Respecting the initial threshold proposed by \citet{kirchenbauer2023watermark}, the Z-Score threshold was $z = 4.0$, based on the gamma and delta previously fixed ($\delta = 5.0, \gamma = 0.25$). 

\section{General points}

These points apply to the whole dissertation, not just this chapter.



\subsection{Figures}
\emph{Always} refer to figures included, like Figure \ref{fig:relu}, in the body of the text. Include full, explanatory captions and make sure the figures look good on the page.
You may include multiple figures in one float, as in Figure \ref{fig:synthetic}, using \texttt{subcaption}, which is enabled in the template.



% Figures are important. Use them well.
\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{images/relu.pdf}    

    \caption{In figure captions, explain what the reader is looking at: ``A schematic of the rectifying linear unit, where $a$ is the output amplitude,
    $d$ is a configurable dead-zone, and $Z_j$ is the input signal'', as well as why the reader is looking at this: 
    ``It is notable that there is no activation \emph{at all} below 0, which explains our initial results.'' 
    \textbf{Use vector image formats (.pdf) where possible}. Size figures appropriately, and do not make them over-large or too small to read.
    }

    % use the notation fig:name to cross reference a figure
    \label{fig:relu} 
\end{figure}


\begin{figure}
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \includegraphics[width=\textwidth]{images/synthetic.png}
        \caption{Synthetic image, black on white.}
        \label{fig:syn1}
    \end{subfigure}
    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
      %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.45\textwidth}
        \includegraphics[width=\textwidth]{images/synthetic_2.png}
        \caption{Synthetic image, white on black.}
        \label{fig:syn2}
    \end{subfigure}
    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
    %(or a blank line to force the subfigure onto a new line)    
    \caption{Synthetic test images for edge detection algorithms. \subref{fig:syn1} shows various gray levels that require an adaptive algorithm. \subref{fig:syn2}
    shows more challenging edge detection tests that have crossing lines. Fusing these into full segments typically requires algorithms like the Hough transform.
    This is an example of using subfigures, with \texttt{subref}s in the caption.
    }\label{fig:synthetic}
\end{figure}

\clearpage

\subsection{Equations}

Equations should be typeset correctly and precisely. Make sure you get parenthesis sizing correct, and punctuate equations correctly 
(the comma is important and goes \textit{inside} the equation block). Explain any symbols used clearly if not defined earlier. 

For example, we might define:
\begin{equation}
    \hat{f}(\xi) = \frac{1}{2}\left[ \int_{-\infty}^{\infty} f(x) e^{2\pi i x \xi} \right],
\end{equation}    
where $\hat{f}(\xi)$ is the Fourier transform of the time domain signal $f(x)$.

\subsection{Algorithms}
Algorithms can be set using \texttt{algorithm2e}, as in Algorithm \ref{alg:metropolis}.

% NOTE: line ends are denoted by \; in algorithm2e
\begin{algorithm}
    \DontPrintSemicolon
    \KwData{$f_X(x)$, a probability density function returing the density at $x$.\; $\sigma$ a standard deviation specifying the spread of the proposal distribution.\;
    $x_0$, an initial starting condition.}
    \KwResult{$s=[x_1, x_2, \dots, x_n]$, $n$ samples approximately drawn from a distribution with PDF $f_X(x)$.}
    \Begin{
        $s \longleftarrow []$\;
        $p \longleftarrow f_X(x)$\;
        $i \longleftarrow 0$\;
        \While{$i < n$}
        {
            $x^\prime \longleftarrow \mathcal{N}(x, \sigma^2)$\;
            $p^\prime \longleftarrow f_X(x^\prime)$\;
            $a \longleftarrow \frac{p^\prime}{p}$\;
            $r \longleftarrow U(0,1)$\;
            \If{$r<a$}
            {
                $x \longleftarrow x^\prime$\;
                $p \longleftarrow f_X(x)$\;
                $i \longleftarrow i+1$\;
                append $x$ to $s$\;
            }
        }
    }
    
\caption{The Metropolis-Hastings MCMC algorithm for drawing samples from arbitrary probability distributions, 
specialised for normal proposal distributions $q(x^\prime|x) = \mathcal{N}(x, \sigma^2)$. The symmetry of the normal distribution means the acceptance rule takes the simplified form.}\label{alg:metropolis}
\end{algorithm}

\subsection{Tables}

If you need to include tables, like Table \ref{tab:operators}, use a tool like https://www.tablesgenerator.com/ to generate the table as it is
extremely tedious otherwise. 

\begin{table}[]
    \caption{The standard table of operators in Python, along with their functional equivalents from the \texttt{operator} package. Note that table
    captions go above the table, not below. Do not add additional rules/lines to tables. }\label{tab:operators}
    %\tt 
    \rowcolors{2}{}{gray!3}
    \begin{tabular}{@{}lll@{}}
    %\toprule
    \textbf{Operation}    & \textbf{Syntax}                & \textbf{Function}                            \\ %\midrule % optional rule for header
    Addition              & \texttt{a + b}                          & \texttt{add(a, b)}                                    \\
    Concatenation         & \texttt{seq1 + seq2}                    & \texttt{concat(seq1, seq2)}                           \\
    Containment Test      & \texttt{obj in seq}                     & \texttt{contains(seq, obj)}                           \\
    Division              & \texttt{a / b}                          & \texttt{div(a, b) }  \\
    Division              & \texttt{a / b}                          & \texttt{truediv(a, b) } \\
    Division              & \texttt{a // b}                         & \texttt{floordiv(a, b)}                               \\
    Bitwise And           & \texttt{a \& b}                         & \texttt{and\_(a, b)}                                  \\
    Bitwise Exclusive Or  & \texttt{a \textasciicircum b}           & \texttt{xor(a, b)}                                    \\
    Bitwise Inversion     & \texttt{$\sim$a}                        & \texttt{invert(a)}                                    \\
    Bitwise Or            & \texttt{a | b}                          & \texttt{or\_(a, b)}                                   \\
    Exponentiation        & \texttt{a ** b}                         & \texttt{pow(a, b)}                                    \\
    Identity              & \texttt{a is b}                         & \texttt{is\_(a, b)}                                   \\
    Identity              & \texttt{a is not b}                     & \texttt{is\_not(a, b)}                                \\
    Indexed Assignment    & \texttt{obj{[}k{]} = v}                 & \texttt{setitem(obj, k, v)}                           \\
    Indexed Deletion      & \texttt{del obj{[}k{]}}                 & \texttt{delitem(obj, k)}                              \\
    Indexing              & \texttt{obj{[}k{]}}                     & \texttt{getitem(obj, k)}                              \\
    Left Shift            & \texttt{a \textless{}\textless b}       & \texttt{lshift(a, b)}                                 \\
    Modulo                & \texttt{a \% b}                         & \texttt{mod(a, b)}                                    \\
    Multiplication        & \texttt{a * b}                          & \texttt{mul(a, b)}                                    \\
    Negation (Arithmetic) & \texttt{- a}                            & \texttt{neg(a)}                                       \\
    Negation (Logical)    & \texttt{not a}                          & \texttt{not\_(a)}                                     \\
    Positive              & \texttt{+ a}                            & \texttt{pos(a)}                                       \\
    Right Shift           & \texttt{a \textgreater{}\textgreater b} & \texttt{rshift(a, b)}                                 \\
    Sequence Repetition   & \texttt{seq * i}                        & \texttt{repeat(seq, i)}                               \\
    Slice Assignment      & \texttt{seq{[}i:j{]} = values}          & \texttt{setitem(seq, slice(i, j), values)}            \\
    Slice Deletion        & \texttt{del seq{[}i:j{]}}               & \texttt{delitem(seq, slice(i, j))}                    \\
    Slicing               & \texttt{seq{[}i:j{]}}                   & \texttt{getitem(seq, slice(i, j))}                    \\
    String Formatting     & \texttt{s \% obj}                       & \texttt{mod(s, obj)}                                  \\
    Subtraction           & \texttt{a - b}                          & \texttt{sub(a, b)}                                    \\
    Truth Test            & \texttt{obj}                            & \texttt{truth(obj)}                                   \\
    Ordering              & \texttt{a \textless b}                  & \texttt{lt(a, b)}                                     \\
    Ordering              & \texttt{a \textless{}= b}               & \texttt{le(a, b)}                                     \\
    % \bottomrule
    \end{tabular}
    \end{table}
\subsection{Code}

Avoid putting large blocks of code in the report (more than a page in one block, for example). Use syntax highlighting if possible, as in Listing \ref{lst:callahan}.

\begin{lstlisting}[language=python, float, caption={The algorithm for packing the $3\times 3$ outer-totalistic binary CA successor rule into a 
    $16\times 16\times 16\times 16$ 4 bit lookup table, running an equivalent, notionally 16-state $2\times 2$ CA.}, label=lst:callahan]
    def create_callahan_table(rule="b3s23"):
        """Generate the lookup table for the cells."""        
        s_table = np.zeros((16, 16, 16, 16), dtype=np.uint8)
        birth, survive = parse_rule(rule)

        # generate all 16 bit strings
        for iv in range(65536):
            bv = [(iv >> z) & 1 for z in range(16)]
            a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p = bv

            # compute next state of the inner 2x2
            nw = apply_rule(f, a, b, c, e, g, i, j, k)
            ne = apply_rule(g, b, c, d, f, h, j, k, l)
            sw = apply_rule(j, e, f, g, i, k, m, n, o)
            se = apply_rule(k, f, g, h, j, l, n, o, p)

            # compute the index of this 4x4
            nw_code = a | (b << 1) | (e << 2) | (f << 3)
            ne_code = c | (d << 1) | (g << 2) | (h << 3)
            sw_code = i | (j << 1) | (m << 2) | (n << 3)
            se_code = k | (l << 1) | (o << 2) | (p << 3)

            # compute the state for the 2x2
            next_code = nw | (ne << 1) | (sw << 2) | (se << 3)

            # get the 4x4 index, and write into the table
            s_table[nw_code, ne_code, sw_code, se_code] = next_code

        return s_table

\end{lstlisting}

%==================================================================================================================================
\chapter{Results} 
How good is your solution? How well did you solve the general problem, and what evidence do you have to support that?

\section{Guidance}
\begin{itemize}
    \item
        Ask specific questions that address the general problem.
    \item
        Answer them with precise evidence (graphs, numbers, statistical
        analysis, qualitative analysis).
    \item
        Be fair and be scientific.
    \item
        The key thing is to show that you know how to evaluate your work, not
        that your work is the most amazing product ever.
\end{itemize}

\section{Evidence}
Make sure you present your evidence well. Use appropriate visualisations, reporting techniques and statistical analysis, as appropriate.

If you visualise, follow the basic rules, as illustrated in Figure \ref{fig:boxplot}:
\begin{itemize}
\item Label everything correctly (axis, title, units).
\item Caption thoroughly.
\item Reference in text.
\item \textbf{Include appropriate display of uncertainty (e.g. error bars, Box plot)}
\item Minimize clutter.
\end{itemize}

See the file \texttt{guide\_to\_visualising.pdf} for further information and guidance.

\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{images/boxplot_finger_distance.pdf}    

    \caption{Average number of fingers detected by the touch sensor at different heights above the surface, averaged over all gestures. Dashed lines indicate
    the true number of fingers present. The Box plots include bootstrapped uncertainty notches for the median. It is clear that the device is biased toward 
    undercounting fingers, particularly at higher $z$ distances.
    }

    % use the notation fig:name to cross reference a figure
    \label{fig:boxplot} 
\end{figure}


%==================================================================================================================================

\chapter{Related Work}
Background will discuss relevant information to understand this project. Related work will discuss other approaches to the topic.

%==================================================================================================================================
\chapter{Conclusion}    
Summarise the whole project for a lazy reader who didn't read the rest (e.g. a prize-awarding committee).
\section{Guidance}
\begin{itemize}
    \item
        Summarise briefly and fairly.
    \item
        You should be addressing the general problem you introduced in the
        Introduction.        
    \item
        Include summary of concrete results (``the new compiler ran 2x
        faster'')
    \item
        Indicate what future work could be done, but remember: \textbf{you
        won't get credit for things you haven't done}.
\end{itemize}

%==================================================================================================================================
%
% 
%==================================================================================================================================
%  APPENDICES  

\begin{appendices}

\chapter{Appendices}

Typical inclusions in the appendices are:

\begin{itemize}
\item
  Copies of ethics approvals (required if obtained)
\item
  Copies of questionnaires etc. used to gather data from subjects.
\item
  Extensive tables or figures that are too bulky to fit in the main body of
  the report, particularly ones that are repetitive and summarised in the body.

\item Outline of the source code (e.g. directory structure), or other architecture documentation like class diagrams.

\item User manuals, and any guides to starting/running the software.

\end{itemize}

\textbf{Don't include your source code in the appendices}. It will be
submitted separately.

\end{appendices}

%==================================================================================================================================
%   BIBLIOGRAPHY   

% The bibliography style is abbrvnat
% The bibliography always appears last, after the appendices.

\bibliographystyle{abbrvnat}

\bibliography{l4proj}

\end{document}
